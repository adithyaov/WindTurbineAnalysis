{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "___\n",
    "\n",
    "**Specifying the Data**  \n",
    "A data file should containg the data for a specific Machine, and the coulmn names should be one of the following:  \n",
    "Active Power Column: **ActivePower**  \n",
    "Wind Speed Column: **WindSpeed**  \n",
    "Rotor Speed Column: **RotorSpeed**  \n",
    "Pitch Angle Column: **PitchAngle**  \n",
    "Turbine State Column: **TurbineState**\n",
    "\n",
    "(_Applies only to RotorSpeed vs ActivePower_) The file should contain atleast **1 month** and atmost **3 months** of data (According to what I have worked with). According to average WindSpeed, the classification make more sense.\n",
    "\n",
    "___\n",
    "___\n",
    "___\n",
    "\n",
    "### Pitch Angle vs Active Power\n",
    "\n",
    "**How it works**  \n",
    "The **main** function give a specific score to the data.  \n",
    "Depending on the score, the data can be classified.\n",
    "\n",
    "**Dependencies**  \n",
    "1. [numpy][numpy link]: Fundamental package for scientific computing with Python.\n",
    "2. [pandas][pandas link]: Library providing high-performance, easy-to-use data structures and data analysis tools for the Python.\n",
    "3. [sklearn.cluster.DBSCAN][dbscan link]: Clustring algorithm, (**D**ensity-**b**ased **s**patial **c**lustering of **a**pplications with **n**oise).\n",
    "4. [matplotlib.pyplot][pyplot link]: Python 2D plotting library.\n",
    "\n",
    "___\n",
    "\n",
    "**Function:** def main(...):  \n",
    "_Main Function_\n",
    "\n",
    "**Parameters:**  \n",
    "_Arguments default to Chakla_\n",
    "1. filePath\n",
    "    * Path of the file for running the function on.\n",
    "    * File Format should be **csv**.\n",
    "    * Should contain data on: PitchAngle, ActivePower, TurbineState.\n",
    "2. xMinFilter\n",
    "    * Essentially cropping the data.\n",
    "    * The x-offset min value, ie. The valid least PitchAngle value to crop from.\n",
    "    * Default value: **-2.82**\n",
    "3. xMaxFilter\n",
    "    * Essentially cropping the data.\n",
    "    * The x-offset max value, ie. The valid highest PitchAngle value to crop to.\n",
    "    * Default value: **1.18**\n",
    "4. yMinFilter\n",
    "    * Essentially cropping the data.\n",
    "    * The y-offset min value, ie. The valid least ActivePower value to crop from.\n",
    "    * Default value: **188**\n",
    "5. yMaxFilter\n",
    "    * Essentially cropping the data.\n",
    "    * The y-offset max value, ie. The valid highest ActivePower value to crop to.\n",
    "    * Default value: **1047**\n",
    "6. turbineStateFilter\n",
    "    * Valid Turbine State to filter proper data.\n",
    "    * Default value: **11**\n",
    "7. dbscanEps\n",
    "    * The variable **eps** for the DBSCAN Clustring Algorithm, used to **filter the noise**.\n",
    "    * ref: [sklearn.cluster.DBSCAN][dbscan link]\n",
    "    * Default value: **3**\n",
    "8. dbscanMinSamples\n",
    "    * The variable **min_samples** for the DBSCAN Clustring Algorithm, used to **filter the noise**.\n",
    "    * ref: [sklearn.cluster.DBSCAN][dbscan link]\n",
    "    * Default value: **4**\n",
    "9. roundingMult\n",
    "    * Variable used in the function **def rounding(mult, div):**\n",
    "    * The value to multiply to the scaled value _(for discretizing)_.\n",
    "    * Default value: **2**\n",
    "10. roundingDiv\n",
    "    * Variable used in the function **def rounding(mult, div):**\n",
    "    * The value to divide the scaled value after multiplyting _(for discretizing)_, then converted to **int** format.\n",
    "    * Default value: **1**\n",
    "11. maxSpacePositionLimits\n",
    "    * A tuple defining the positional limits of the max space. (max gap in between the points).\n",
    "    * Default value: **(0.2, 0.8)**\n",
    "12. limitMaxScore\n",
    "    * A limiting value to the score in each discritized line.\n",
    "    * Used to avoid abnotmal scores.\n",
    "    * Default value: **8**\n",
    "13. limitGrpSize\n",
    "    * A limiting value for the size of the group that the DBSCAN acts on.\n",
    "    * Default value: **2**\n",
    "14. plotGraph\n",
    "    * Expects a BOOLEAN.\n",
    "        * True: Prints Graph\n",
    "        * False: Does not print Graph\n",
    "    * Default value: **False**\n",
    "\n",
    "**Return Value:**  \n",
    "_A Python [dictionary][python dict link]_  \n",
    "* filePath: The complete path of the input File.\n",
    "* instances: The number of valid discrete points used in computation.\n",
    "* maxInstances: The number of valid discrete points possible.\n",
    "* maxScorePossible: The max score if maxInstances were used.\n",
    "* maxScore: The max score if valid instances are used.\n",
    "* score: The computed score.\n",
    "\n",
    "___\n",
    "\n",
    "**Function:** def rounding(...):  \n",
    "_Used in discritizing the scaled values_  \n",
    "\n",
    "**Parameters**\n",
    "1. mult\n",
    "    * Default value: 1\n",
    "2. div\n",
    "    * Default value: 2\n",
    "\n",
    "**Defination:**  \n",
    "int(**number** * mult / div)\n",
    "\n",
    "___  \n",
    "___\n",
    "___\n",
    "\n",
    "\n",
    "### Rotor Speed vs Active Power\n",
    "\n",
    "**How it works**  \n",
    "The **main** function gives specific numbers correcponding to the Data.  \n",
    "Depending on the values of the numbers, the data can be classified.\n",
    "\n",
    "**Dependencies**  \n",
    "1. [numpy][numpy link]: Fundamental package for scientific computing with Python.\n",
    "2. [pandas][pandas link]: Library providing high-performance, easy-to-use data structures and data analysis tools for the Python.\n",
    "3. [sklearn.cluster.DBSCAN][dbscan link]: Clustring algorithm, (**D**ensity-**b**ased **s**patial **c**lustering of **a**pplications with **n**oise).\n",
    "4. [matplotlib.pyplot][pyplot link]: Python 2D plotting library.\n",
    "5. [scipy.stats][scipy stats link]: Module containing large number of _probability distributions_ as well as _statistical functions_.\n",
    "\n",
    "___\n",
    "\n",
    "**Function:** def main(...):  \n",
    "_Main Function_\n",
    "\n",
    "**Parameters:**  \n",
    "_Arguments default to Burgula_\n",
    "1. filePath\n",
    "    * Path of the file for running the function on.\n",
    "    * File Format should be **csv**.\n",
    "    * Should contain data on: RotorSpeed, ActivePower, TurbineState.\n",
    "2. xMinFilter\n",
    "    * Essentially cropping the data.\n",
    "    * The x-offset min value, ie. The valid least RotorSpeed value to crop from.\n",
    "    * Default value: **21**\n",
    "3. xMaxFilter\n",
    "    * Essentially cropping the data.\n",
    "    * The x-offset max value, ie. The valid highest RotorSpeed value to crop to.\n",
    "    * Default value: **25**\n",
    "4. yMinFilter\n",
    "    * Essentially cropping the data.\n",
    "    * The y-offset min value, ie. The valid least ActivePower value to crop from.\n",
    "    * Default value: **0**\n",
    "6. turbineStateFilter\n",
    "    * Valid Turbine State to filter proper data.\n",
    "    * Default value: **100**\n",
    "7. dbscanEps\n",
    "    * The variable **eps** for the DBSCAN Clustring Algorithm, used to **filter the noise**.\n",
    "    * ref: [sklearn.cluster.DBSCAN][dbscan link]\n",
    "    * Default value: **2**\n",
    "8. dbscanMinSamples\n",
    "    * The variable **min_samples** for the DBSCAN Clustring Algorithm, used to **filter the noise**.\n",
    "    * ref: [sklearn.cluster.DBSCAN][dbscan link]\n",
    "    * Default value: **4**\n",
    "9. rotationAngle\n",
    "    * The angle(in degrees) by which the axis should be rotated clockwise, so that the data transforms into a straight line.\n",
    "    * Default value: **24**\n",
    "10. blockSize\n",
    "    * The size of the block used in the computation of the stats([kurtosis][kurtosis link]).\n",
    "    * Default value: **10**\n",
    "11. plotGraph\n",
    "    * Expects a BOOLEAN.\n",
    "        * True: Prints Graph\n",
    "        * False: Does not print Graph\n",
    "    * Default value: **False**\n",
    "    \n",
    "**Return Value:**  \n",
    "_A Python [dictionary][python dict link]_  \n",
    "* filePath: The complete path of the input File.\n",
    "* positiveInstances: The number of instances that gave a positive [kurtosis][kurtosis link] value.\n",
    "* positiveScore: The positive kurosis summation.\n",
    "* negativeInstances: The number of instances that gave a negative [kurtosis][kurtosis link] value.\n",
    "* negativeScore: The negative kurosis summation.\n",
    "\n",
    "_The complete score would be, **positiveScore + negativeScore**_, but sometimes it is nessary to take the number of instances into account too.\n",
    "\n",
    "___\n",
    "___\n",
    "___\n",
    "\n",
    "### Wind Speed vs Active Power\n",
    "\n",
    "**How it works**  \n",
    "The **main** function gives a performance drop score correcponding to the Data.  \n",
    "Depending on that score, the data can be classified.\n",
    "\n",
    "**Dependencies**  \n",
    "1. [numpy][numpy link]: Fundamental package for scientific computing with Python.\n",
    "2. [pandas][pandas link]: Library providing high-performance, easy-to-use data structures and data analysis tools for the Python.\n",
    "3. [sklearn.cluster.DBSCAN][dbscan link]: Clustring algorithm, (**D**ensity-**b**ased **s**patial **c**lustering of **a**pplications with **n**oise).\n",
    "4. [matplotlib.pyplot][pyplot link]: Python 2D plotting library.\n",
    "\n",
    "___\n",
    "\n",
    "**Function:** def main(...):  \n",
    "_Main Function_\n",
    "\n",
    "**Parameters:**  \n",
    "_Arguments default to Mokal_\n",
    "1. filePath\n",
    "    * Path of the file for running the function on.\n",
    "    * File Format should be **csv**.\n",
    "    * Should contain data on: WindSpeed, ActivePower, TurbineState.\n",
    "2. turbineStateFilter\n",
    "    * Valid Turbine State to filter proper data.\n",
    "    * Default value: **11**\n",
    "3. roundingMult\n",
    "    * Variable used in the function **def rounding(mult, div):**\n",
    "    * The value to multiply to the scaled value _(for discretizing)_.\n",
    "    * Default value: **2**\n",
    "4. roundingDiv\n",
    "    * Variable used in the function **def rounding(mult, div):**\n",
    "    * The value to divide the scaled value after multiplyting _(for discretizing)_, then converted to **int** format.\n",
    "    * Default value: **1**\n",
    "5. dbscanErrorEps\n",
    "    * The variable **eps** for the DBSCAN Clustring Algorithm, used to **filter the noise**.\n",
    "    * ref: [sklearn.cluster.DBSCAN][dbscan link]\n",
    "    * Default value: **2**\n",
    "6. dbscanErrorMinSamples\n",
    "    * The variable **min_samples** for the DBSCAN Clustring Algorithm, used to **filter the noise**.\n",
    "    * ref: [sklearn.cluster.DBSCAN][dbscan link]\n",
    "    * Default value: **4**\n",
    "7. yMinFilter\n",
    "    * Essentially cropping the data.\n",
    "    * The y-offset min value, ie. The valid least ActivePower value to crop from.\n",
    "    * Default value: **107**\n",
    "8. dbscanDegradeEps\n",
    "    * The variable **eps** for the DBSCAN Clustring Algorithm, used to **find the degraded points**.\n",
    "    * Only for clustring, does not give a **-1** label.\n",
    "    * ref: [sklearn.cluster.DBSCAN][dbscan link]\n",
    "    * Default value: **4**\n",
    "9. dbscanDegradeMinSamples\n",
    "    * The variable **min_samples** for the DBSCAN Clustring Algorithm, used to **find the degraded points**.\n",
    "    * Only for clustring, does not give a **-1** label.\n",
    "    * ref: [sklearn.cluster.DBSCAN][dbscan link]\n",
    "    * Default value: **0**\n",
    "10. dummyInputXMin\n",
    "    * The expected WindSpeed from with the ActivePower is supposed to be maximum.\n",
    "    * Default value: **13**\n",
    "11. scaledActivePowerStdLimit\n",
    "    * The maximum deviation in performance which is allowed.\n",
    "    * Default value: **4**\n",
    "12. grpSizeLimit\n",
    "    * The minimum number of power points at a specific WindSpeed for computation.\n",
    "    * Default value: **5**\n",
    "13. plotGraph\n",
    "    * Expects a BOOLEAN.\n",
    "        * True: Prints Graph\n",
    "        * False: Does not print Graph\n",
    "    * Default value: **False**\n",
    "    \n",
    "**Return Value:**  \n",
    "_A Python [dictionary][python dict link]_  \n",
    "* filePath: The complete path of the input File.\n",
    "* performanceDropScore: The complete path of the input File.\n",
    "* dropInstances: The number of valid discrete points used in computation of Performance Drop.\n",
    "* activePowerStdScore: The summation of [standard deviation][std link] of ActivePower at ever discrete WindSpeed\n",
    "* activePowerStdInstances: The number of valid discrete points used in computation of [standard deviation][std link].\n",
    "* abnormalPerformancePoints: [DataFrame][pandas dataframe link] of possible abnormal points.\n",
    "* filteredErrorPointsDbscan: [DataFrame][pandas dataframe link] of points filtered by DBSCAN as errors.\n",
    "* duplicatedPoints: [DataFrame][pandas dataframe link] of points which are duplicated.\n",
    "___\n",
    "\n",
    "**Function:** def rounding(...):  \n",
    "_Used in discritizing the scaled values_  \n",
    "\n",
    "**Parameters**\n",
    "1. mult\n",
    "    * Default value: 1\n",
    "2. div\n",
    "    * Default value: 2\n",
    "\n",
    "**Defination:**  \n",
    "int(**number** * mult / div)\n",
    "\n",
    "___\n",
    "___\n",
    "___\n",
    "\n",
    "**Additional Description**\n",
    "1. **eps**: The radius that you want to consider for judging point validity.\n",
    "2. **min_samples**: The number of points inside the eps, for considering the point valid\n",
    "3. **~MinFilter**: Used for cropping the data. Essentially the offset value.\n",
    "4. **How did _4_ come in dbscanDegradeEps?**:  \n",
    "    The ActivePower ranges form 0 - 2000.  \n",
    "    It is scaled from 0 - 100, ie. reduced by a factor of 20.  \n",
    "    The valid performance decrease is, say **x** then scale that **x**, by the reduced factor, in this case is 20.\n",
    "5. **dbscanDegradeMinSamples**: Is **0** most of the time.\n",
    "\n",
    "___\n",
    "___\n",
    "___\n",
    "\n",
    "[pandas dataframe link]: pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
    "[python dict link]: https://docs.python.org/2/tutorial/datastructures.html#dictionaries\n",
    "[numpy link]: http://www.numpy.org/\n",
    "[pandas link]: http://pandas.pydata.org\n",
    "[dbscan link]: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html\n",
    "[pyplot link]: http://matplotlib.org/api/pyplot_summary.html\n",
    "[scipy stats link]: https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "[kurtosis link]: https://en.wikipedia.org/wiki/Kurtosis\n",
    "[std link]: https://en.wikipedia.org/wiki/Standard_deviation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mytrah",
   "language": "python",
   "name": "mytrah"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
